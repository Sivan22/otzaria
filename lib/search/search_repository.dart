import 'dart:math' as math;
import 'package:otzaria/data/data_providers/tantivy_data_provider.dart';
import 'package:otzaria/search/utils/regex_patterns.dart';
import 'package:otzaria/search/services/search_isolate_service.dart';
import 'package:search_engine/search_engine.dart';

/// Performs a search operation across indexed texts.
///
/// [query] The search query string
/// [facets] List of facets to search within
/// [limit] Maximum number of results to return
/// [order] Sort order for results
/// [fuzzy] Whether to perform fuzzy matching
/// [distance] Default distance between words (slop)
/// [customSpacing] Custom spacing between specific word pairs
/// [alternativeWords] Alternative words for each word position (OR queries)
/// [searchOptions] Search options for each word (prefixes, suffixes, etc.)
///
/// Returns a Future containing a list of search results
///
class SearchRepository {
  Future<List<SearchResult>> searchTexts(
      String query, List<String> facets, int limit,
      {ResultsOrder order = ResultsOrder.relevance,
      bool fuzzy = false,
      int distance = 2,
      Map<String, String>? customSpacing,
      Map<int, List<String>>? alternativeWords,
      Map<String, Map<String, bool>>? searchOptions}) async {
    print('ğŸš€ searchTexts called with query: "$query"');

    // ×‘×“×™×§×ª ×•×¨×™××¦×™×•×ª ×›×ª×™×‘ ××œ×/×—×¡×¨
    print('ğŸ” Testing spelling variations for "×¨××©×™×ª":');
    final testVariations =
        SearchRegexPatterns.generateFullPartialSpellingVariations('×¨××©×™×ª');
    print('   variations: $testVariations');

    // ×‘×“×™×§×ª createPrefixPattern ×¢×‘×•×¨ ×›×œ ×•×¨×™××¦×™×”
    for (final variation in testVariations) {
      final prefixPattern = SearchRegexPatterns.createPrefixPattern(variation);
      print('   $variation -> $prefixPattern');
    }

    // ×‘×“×™×§×ª createSpellingWithPrefixPattern
    final finalPattern =
        SearchRegexPatterns.createSpellingWithPrefixPattern('×¨××©×™×ª');
    print('ğŸ” Final createSpellingWithPrefixPattern result: $finalPattern');
    // ×‘×“×™×§×” ×× ×”××™× ×“×§×¡ ×¨×¥ - ×× ×›×Ÿ, × ×©×ª××© ×‘-Isolate ×œ×—×™×¤×•×©
    final isIndexing = TantivyDataProvider.instance.isIndexing.value;

    if (isIndexing) {
      print('ğŸ”„ Indexing in progress, using isolate search service');
      // ×©×™××•×© ×‘-SearchIsolateService ×›×©×”××™× ×“×§×¡ ×¨×¥
      final isolateSearchOptions = SearchOptions(
        fuzzy: fuzzy,
        distance: distance,
        customSpacing: customSpacing,
        alternativeWords: alternativeWords,
        searchOptions: searchOptions,
        order: order,
      );

      final resultWrapper = await SearchIsolateService.searchTexts(
        query,
        facets,
        limit,
        isolateSearchOptions,
      );

      if (resultWrapper.error != null) {
        print('âŒ Search isolate error: ${resultWrapper.error}');
        // fallback ×œ×—×™×¤×•×© ×¨×’×™×œ
        final index = await TantivyDataProvider.instance.engine;
        return await _performDirectSearch(index, query, facets, limit, order,
            fuzzy, distance, customSpacing, alternativeWords, searchOptions);
      }

      print(
          'âœ… Isolate search completed, found ${resultWrapper.results.length} results');
      return resultWrapper.results;
    } else {
      // ×©×™××•×© ×¨×’×™×œ ×›×©×”××™× ×“×§×¡ ×œ× ×¨×¥
      final index = await TantivyDataProvider.instance.engine;
      return await _performDirectSearch(index, query, facets, limit, order,
          fuzzy, distance, customSpacing, alternativeWords, searchOptions);
    }
  }

  /// ×‘×™×¦×•×¢ ×—×™×¤×•×© ×™×©×™×¨ (×œ×œ× Isolate)
  Future<List<SearchResult>> _performDirectSearch(
    SearchEngine index,
    String query,
    List<String> facets,
    int limit,
    ResultsOrder order,
    bool fuzzy,
    int distance,
    Map<String, String>? customSpacing,
    Map<int, List<String>>? alternativeWords,
    Map<String, Map<String, bool>>? searchOptions,
  ) async {
    // ×‘×“×™×§×” ×× ×™×© ××¨×•×•×—×™× ××•×ª×××™× ××™×©×™×ª, ××™×œ×™× ×—×™×œ×•×¤×™×•×ª ××• ××¤×©×¨×•×™×•×ª ×—×™×¤×•×©
    final hasCustomSpacing = customSpacing != null && customSpacing.isNotEmpty;
    final hasAlternativeWords =
        alternativeWords != null && alternativeWords.isNotEmpty;
    final hasSearchOptions = searchOptions != null &&
        searchOptions.isNotEmpty &&
        searchOptions.values.any((wordOptions) =>
            wordOptions.values.any((isEnabled) => isEnabled == true));

    print('ğŸ” hasSearchOptions: $hasSearchOptions');
    print('ğŸ” hasAlternativeWords: $hasAlternativeWords');

    // ×”××¨×ª ×”×—×™×¤×•×© ×œ×¤×•×¨××˜ ×”×× ×•×¢ ×”×—×“×©
    // ×¡×™× ×•×Ÿ ××—×¨×•×–×•×ª ×¨×™×§×•×ª ×©× ×•×¦×¨×•×ª ×›××©×¨ ×™×© ×¨×•×•×—×™× ×‘×¡×•×£ ×”×©××™×œ×ª×”
    final words = query
        .trim()
        .split(SearchRegexPatterns.wordSplitter)
        .where((word) => word.isNotEmpty)
        .toList();
    final List<String> regexTerms;
    final int effectiveSlop;

    // ×”×•×“×¢×ª ×“×™×‘×•×’ ×œ×‘×“×™×§×ª search options
    if (searchOptions != null && searchOptions.isNotEmpty) {
      print('â¡ï¸Debug search options:');
      for (final entry in searchOptions.entries) {
        print('   ${entry.key}: ${entry.value}');
      }
    }

    if (hasAlternativeWords || hasSearchOptions) {
      // ×™×© ××™×œ×™× ×—×™×œ×•×¤×™×•×ª ××• ××¤×©×¨×•×™×•×ª ×—×™×¤×•×© - × ×‘× ×” queries ××ª×§×“××™×
      print('ğŸ”„ ×‘×•× ×” query ××ª×§×“×');
      if (hasAlternativeWords) print('ğŸ”„ ××™×œ×™× ×—×™×œ×•×¤×™×•×ª: $alternativeWords');
      if (hasSearchOptions) print('ğŸ”„ ××¤×©×¨×•×™×•×ª ×—×™×¤×•×©: $searchOptions');

      regexTerms = _buildAdvancedQuery(words, alternativeWords, searchOptions);
      print('ğŸ”„ RegexTerms ××ª×§×“×: $regexTerms');
      print(
          'ğŸ”„ effectiveSlop will be: ${hasCustomSpacing ? "custom" : (fuzzy ? distance.toString() : "0")}');
      effectiveSlop = hasCustomSpacing
          ? _getMaxCustomSpacing(customSpacing, words.length)
          : (fuzzy ? distance : 0);
    } else if (fuzzy) {
      // ×—×™×¤×•×© ××§×•×¨×‘ - × ×©×ª××© ×‘××™×œ×™× ×‘×•×“×“×•×ª
      regexTerms = words;
      effectiveSlop = distance;
    } else if (words.length == 1) {
      // ××™×œ×” ××—×ª - ×—×™×¤×•×© ×¤×©×•×˜
      regexTerms = [query];
      effectiveSlop = 0;
    } else if (hasCustomSpacing) {
      // ××¨×•×•×—×™× ××•×ª×××™× ××™×©×™×ª
      regexTerms = words;
      effectiveSlop = _getMaxCustomSpacing(customSpacing, words.length);
    } else {
      // ×—×™×¤×•×© ××“×•×™×™×§ ×©×œ ×›××” ××™×œ×™×
      regexTerms = words;
      effectiveSlop = distance;
    }

    // ×—×™×©×•×‘ maxExpansions ×‘×”×ª×‘×¡×¡ ×¢×œ ×¡×•×’ ×”×—×™×¤×•×©
    final int maxExpansions = _calculateMaxExpansions(fuzzy, regexTerms.length,
        searchOptions: searchOptions, words: words);

    print('ğŸ” Final search params:');
    print('   regexTerms: $regexTerms');
    print('   facets: $facets');
    print('   limit: $limit');
    print('   slop: $effectiveSlop');
    print('   maxExpansions: $maxExpansions');
    print('ğŸš€ Calling index.search...');

    final results = await index.search(
        regexTerms: regexTerms,
        facets: facets,
        limit: limit,
        slop: effectiveSlop,
        maxExpansions: maxExpansions,
        order: order);

    print('âœ… Direct search completed, found ${results.length} results');
    return results;
  }

  /// ××—×©×‘ ××ª ×”××¨×•×•×— ×”××§×¡×™××œ×™ ××”××¨×•×•×—×™× ×”××•×ª×××™× ××™×©×™×ª
  int _getMaxCustomSpacing(Map<String, String> customSpacing, int wordCount) {
    int maxSpacing = 0;

    for (int i = 0; i < wordCount - 1; i++) {
      final spacingKey = '$i-${i + 1}';
      final customSpacingValue = customSpacing[spacingKey];

      if (customSpacingValue != null && customSpacingValue.isNotEmpty) {
        final spacingNum = int.tryParse(customSpacingValue) ?? 0;
        maxSpacing = maxSpacing > spacingNum ? maxSpacing : spacingNum;
      }
    }

    return maxSpacing;
  }

  /// ×‘×•× ×” query ××ª×§×“× ×¢× ××™×œ×™× ×—×™×œ×•×¤×™×•×ª ×•××¤×©×¨×•×™×•×ª ×—×™×¤×•×©
  List<String> _buildAdvancedQuery(
      List<String> words,
      Map<int, List<String>>? alternativeWords,
      Map<String, Map<String, bool>>? searchOptions) {
    List<String> regexTerms = [];

    for (int i = 0; i < words.length; i++) {
      final word = words[i];
      final wordKey = '${word}_$i';

      // ×§×‘×œ×ª ××¤×©×¨×•×™×•×ª ×”×—×™×¤×•×© ×œ××™×œ×” ×”×–×•
      final wordOptions = searchOptions?[wordKey] ?? {};
      final hasPrefix = wordOptions['×§×™×“×•××•×ª'] == true;
      final hasSuffix = wordOptions['×¡×™×•××•×ª'] == true;
      final hasGrammaticalPrefixes = wordOptions['×§×™×“×•××•×ª ×“×§×“×•×§×™×•×ª'] == true;
      final hasGrammaticalSuffixes = wordOptions['×¡×™×•××•×ª ×“×§×“×•×§×™×•×ª'] == true;
      final hasFullPartialSpelling = wordOptions['×›×ª×™×‘ ××œ×/×—×¡×¨'] == true;
      final hasPartialWord = wordOptions['×—×œ×§ ×××™×œ×”'] == true;

      // ×§×‘×œ×ª ××™×œ×™× ×—×™×œ×•×¤×™×•×ª
      final alternatives = alternativeWords?[i];

      // ×‘× ×™×™×ª ×¨×©×™××ª ×›×œ ×”××¤×©×¨×•×™×•×ª (××™×œ×” ××§×•×¨×™×ª + ×—×œ×•×¤×•×ª)
      final allOptions = [word];
      if (alternatives != null && alternatives.isNotEmpty) {
        allOptions.addAll(alternatives);
      }

      // ×¡×™× ×•×Ÿ ××¤×©×¨×•×™×•×ª ×¨×™×§×•×ª
      final validOptions =
          allOptions.where((w) => w.trim().isNotEmpty).toList();

      if (validOptions.isNotEmpty) {
        // ×‘× ×™×™×ª ×¨×©×™××ª ×›×œ ×”××¤×©×¨×•×™×•×ª ×œ×›×œ ××™×œ×”
        final allVariations = <String>{};

        for (final option in validOptions) {
          // ×”×©×ª××© ×‘×¤×•× ×§×¦×™×” ×”××©×•×œ×‘×ª ×”×—×“×©×”
          final pattern = SearchRegexPatterns.createSearchPattern(
            option,
            hasPrefix: hasPrefix,
            hasSuffix: hasSuffix,
            hasGrammaticalPrefixes: hasGrammaticalPrefixes,
            hasGrammaticalSuffixes: hasGrammaticalSuffixes,
            hasPartialWord: hasPartialWord,
            hasFullPartialSpelling: hasFullPartialSpelling,
          );
          allVariations.add(pattern);
        }

        // ×”×’×‘×œ×” ×¢×œ ××¡×¤×¨ ×”×•×¨×™××¦×™×•×ª ×”×›×•×œ×œ ×œ××™×œ×” ××—×ª
        final limitedVariations = allVariations.length > 20
            ? allVariations.take(20).toList()
            : allVariations.toList();

        // ×‘××§×•× ×¨×’×§×¡ ××•×¨×›×‘, × ×•×¡×™×£ ×›×œ ×•×¨×™××¦×™×” ×‘× ×¤×¨×“
        final finalPattern = limitedVariations.length == 1
            ? limitedVariations.first
            : '(${limitedVariations.join('|')})';

        regexTerms.add(finalPattern);
        // ×”×•×“×¢×ª ×“×™×‘×•×’ ×¢× ×”×¡×‘×¨ ×¢×œ ×”×œ×•×’×™×§×”
        final searchType = hasPrefix && hasSuffix
            ? '×§×™×“×•××•×ª+×¡×™×•××•×ª (×—×œ×§ ×××™×œ×”)'
            : hasGrammaticalPrefixes && hasGrammaticalSuffixes
                ? '×§×™×“×•××•×ª+×¡×™×•××•×ª ×“×§×“×•×§×™×•×ª'
                : hasPrefix
                    ? '×§×™×“×•××•×ª'
                    : hasSuffix
                        ? '×¡×™×•××•×ª'
                        : hasGrammaticalPrefixes
                            ? '×§×™×“×•××•×ª ×“×§×“×•×§×™×•×ª'
                            : hasGrammaticalSuffixes
                                ? '×¡×™×•××•×ª ×“×§×“×•×§×™×•×ª'
                                : hasPartialWord
                                    ? '×—×œ×§ ×××™×œ×”'
                                    : hasFullPartialSpelling
                                        ? '×›×ª×™×‘ ××œ×/×—×¡×¨'
                                        : '××“×•×™×§';

        print('ğŸ”„ ××™×œ×” $i: $finalPattern (×¡×•×’ ×—×™×¤×•×©: $searchType)');
      } else {
        // fallback ×œ××™×œ×” ×”××§×•×¨×™×ª
        regexTerms.add(word);
      }
    }

    return regexTerms;
  }

  /// ××—×©×‘ ××ª maxExpansions ×‘×”×ª×‘×¡×¡ ×¢×œ ×¡×•×’ ×”×—×™×¤×•×©
  int _calculateMaxExpansions(bool fuzzy, int termCount,
      {Map<String, Map<String, bool>>? searchOptions, List<String>? words}) {
    // ×‘×“×™×§×” ×× ×™×© ×—×™×¤×•×© ×¢× ×¡×™×•××•×ª ××• ×§×™×“×•××•×ª ×•××™×–×” ××™×œ×™×
    bool hasSuffixOrPrefix = false;
    int shortestWordLength = 10; // ×¢×¨×š ×”×ª×—×œ×ª×™ ×’×‘×•×”

    if (searchOptions != null && words != null) {
      for (int i = 0; i < words.length; i++) {
        final word = words[i];
        final wordKey = '${word}_$i';
        final wordOptions = searchOptions[wordKey] ?? {};

        if (wordOptions['×¡×™×•××•×ª'] == true ||
            wordOptions['×§×™×“×•××•×ª'] == true ||
            wordOptions['×§×™×“×•××•×ª ×“×§×“×•×§×™×•×ª'] == true ||
            wordOptions['×¡×™×•××•×ª ×“×§×“×•×§×™×•×ª'] == true ||
            wordOptions['×—×œ×§ ×××™×œ×”'] == true) {
          hasSuffixOrPrefix = true;
          shortestWordLength = math.min(shortestWordLength, word.length);
        }
      }
    }

    if (fuzzy) {
      return 50; // ×—×™×¤×•×© ××§×•×¨×‘
    } else if (hasSuffixOrPrefix) {
      // ×”×ª×××ª ×”××’×‘×œ×” ×œ×¤×™ ××•×¨×š ×”××™×œ×” ×”×§×¦×¨×” ×‘×™×•×ª×¨ ×¢× ××¤×©×¨×•×™×•×ª ××ª×§×“××•×ª
      if (shortestWordLength <= 1) {
        return 2000; // ××™×œ×” ×©×œ ×ª×• ××—×“ - ×”×’×‘×œ×” ×§×™×¦×•× ×™×ª
      } else if (shortestWordLength <= 2) {
        return 3000; // ××™×œ×” ×©×œ 2 ×ª×•×•×™× - ×”×’×‘×œ×” ×‘×™× ×•× ×™×ª
      } else if (shortestWordLength <= 3) {
        return 4000; // ××™×œ×” ×©×œ 3 ×ª×•×•×™× - ×”×’×‘×œ×” ×§×œ×”
      } else {
        return 5000; // ××™×œ×” ××¨×•×›×” - ×”×’×‘×œ×” ××œ××”
      }
    } else if (termCount > 1) {
      return 100; // ×—×™×¤×•×© ×©×œ ×›××” ××™×œ×™× - ×¦×¨×™×š expansions ×’×‘×•×” ×™×•×ª×¨
    } else {
      return 10; // ××™×œ×” ××—×ª - expansions × ××•×š
    }
  }
}
